{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"samuelcortinhas/cats-and-dogs-image-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsLceJCi6eWg",
        "outputId": "e934753c-b497-4983-cfc1-7fb6705bfe85"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/samuelcortinhas/cats-and-dogs-image-classification?dataset_version_number=4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64.4M/64.4M [00:00<00:00, 91.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/samuelcortinhas/cats-and-dogs-image-classification/versions/4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 1: Import libraries ===\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "_0rC8I3k_c8R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths (adjust these paths as necessary)\n",
        "DATASET_PATH = '/root/.cache/kagglehub/datasets/samuelcortinhas/cats-and-dogs-image-classification/versions/4'\n",
        "TRAIN_PATH = os.path.join(DATASET_PATH, 'train')\n",
        "TEST_PATH = os.path.join(DATASET_PATH, 'test')"
      ],
      "metadata": {
        "id": "nI6WMlmW_gkA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image parameters\n",
        "IMG_WIDTH, IMG_HEIGHT = 128, 128  # You can adjust as needed\n",
        "CHANNELS = 3  # Use 1 for grayscale or 3 for RGB"
      ],
      "metadata": {
        "id": "SpHSvO1Z_oNE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2: Data Loading and Preprocessing for scikit-learn models ===\n",
        "def load_images(path, img_size=(IMG_WIDTH, IMG_HEIGHT), flatten=True, color=True):\n",
        "    images = []\n",
        "    labels = []\n",
        "    classes = ['cats', 'dogs']\n",
        "    for label in classes:\n",
        "        folder = os.path.join(path, label)\n",
        "        for img_path in glob(os.path.join(folder, '*.jpeg')) + glob(os.path.join(folder, '*.jpg')) + glob(os.path.join(folder, '*.png')):\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "            if color:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            else:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, img_size)\n",
        "            if flatten:\n",
        "                img = img.flatten()\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n"
      ],
      "metadata": {
        "id": "TUP6kcOb_w8K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data for traditional ML models (using grayscale for simplicity)\n",
        "X, y = load_images(TRAIN_PATH, flatten=True, color=False)\n",
        "print(\"Loaded training images for traditional models:\", X.shape)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Scale pixel values\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X.astype('float32'))\n",
        "\n",
        "# Split into train/validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CxSqaJN_1Xf",
        "outputId": "6aa995bb-4346-4688-ab76-4ef052cfc71f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded training images for traditional models: (557, 16384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 3: Train scikit-learn models ===\n",
        "# SVM\n",
        "svm_model = SVC(probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_val)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred = rf_model.predict(X_val)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "\n",
        "# Logistic Regression\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred = lr_model.predict(X_val)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "\n",
        "# K-means Clustering (unsupervised – note: this won’t directly predict labels)\n",
        "kmeans_model = KMeans(n_clusters=2, random_state=42)\n",
        "kmeans_model.fit(X_train)\n",
        "# For demonstration, we assign clusters to labels (this is heuristic)\n",
        "print(\"K-means clustering centers:\", kmeans_model.cluster_centers_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKE2rkOT_8zQ",
        "outputId": "064e325b-3de3-42a2-9ad5-5b5ed7f67fcf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.5625\n",
            "Random Forest Accuracy: 0.5982142857142857\n",
            "Logistic Regression Accuracy: 0.5714285714285714\n",
            "K-means clustering centers: [[ 0.7147157   0.7126295   0.71017164 ...  0.74235755  0.7440248\n",
            "   0.74322426]\n",
            " [-0.48604226 -0.4907742  -0.49254894 ... -0.50438845 -0.5145112\n",
            "  -0.5062493 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the scikit-learn models\n",
        "os.makedirs('/content/models', exist_ok=True)\n",
        "joblib.dump(svm_model, '/content/models/svm_model.pkl')\n",
        "joblib.dump(rf_model, '/content/models/rf_model.pkl')\n",
        "joblib.dump(lr_model, '/content/models/lr_model.pkl')\n",
        "joblib.dump(kmeans_model, '/content/models/kmeans_model.pkl')\n",
        "joblib.dump(scaler, '/content/models/scaler.pkl')\n",
        "joblib.dump(le, '/content/models/label_encoder.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA9PKoucAQUi",
        "outputId": "d8e242b4-6dd2-43ca-f7fd-a2a576489838"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/models/label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 4: Data Loading and Preprocessing for CNN ===\n",
        "# Use ImageDataGenerator for CNN – assuming images are in color.\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QBnoRIXAsOt",
        "outputId": "b2b1cf49-c0d0-4373-d322-b62aa84ebcc5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 447 images belonging to 2 classes.\n",
            "Found 110 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 5: Build and Train CNN Model ===\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS)),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(train_generator, epochs=100, validation_data=validation_generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3zdDmovAttg",
        "outputId": "fc834eff-c09a-41ab-d933-0525253a5096"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.5657 - loss: 1.1616 - val_accuracy: 0.5000 - val_loss: 0.6821\n",
            "Epoch 2/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.5168 - loss: 0.6702 - val_accuracy: 0.5091 - val_loss: 0.6912\n",
            "Epoch 3/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.6357 - loss: 0.6633 - val_accuracy: 0.5818 - val_loss: 0.6964\n",
            "Epoch 4/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.7127 - loss: 0.5822 - val_accuracy: 0.5818 - val_loss: 0.6730\n",
            "Epoch 5/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.8028 - loss: 0.5020 - val_accuracy: 0.5545 - val_loss: 0.6935\n",
            "Epoch 6/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.8396 - loss: 0.3941 - val_accuracy: 0.6636 - val_loss: 0.6547\n",
            "Epoch 7/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.9131 - loss: 0.2585 - val_accuracy: 0.6364 - val_loss: 0.6932\n",
            "Epoch 8/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9569 - loss: 0.1653 - val_accuracy: 0.6909 - val_loss: 0.7033\n",
            "Epoch 9/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9801 - loss: 0.1133 - val_accuracy: 0.6455 - val_loss: 0.8720\n",
            "Epoch 10/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9844 - loss: 0.0682 - val_accuracy: 0.6636 - val_loss: 0.8380\n",
            "Epoch 11/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.9699 - loss: 0.0938 - val_accuracy: 0.6000 - val_loss: 1.0265\n",
            "Epoch 12/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9862 - loss: 0.0433 - val_accuracy: 0.6455 - val_loss: 0.9678\n",
            "Epoch 13/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9959 - loss: 0.0286 - val_accuracy: 0.6727 - val_loss: 1.0048\n",
            "Epoch 14/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9931 - loss: 0.0283 - val_accuracy: 0.6727 - val_loss: 1.0579\n",
            "Epoch 15/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.9985 - loss: 0.0153 - val_accuracy: 0.7273 - val_loss: 1.1251\n",
            "Epoch 16/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.7091 - val_loss: 1.2393\n",
            "Epoch 17/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.7000 - val_loss: 1.1441\n",
            "Epoch 18/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9995 - loss: 0.0062 - val_accuracy: 0.6818 - val_loss: 1.2592\n",
            "Epoch 19/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.6545 - val_loss: 1.4095\n",
            "Epoch 20/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.6818 - val_loss: 1.2749\n",
            "Epoch 21/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.6909 - val_loss: 1.4037\n",
            "Epoch 22/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.6909 - val_loss: 1.4131\n",
            "Epoch 23/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9990 - loss: 0.0059 - val_accuracy: 0.6545 - val_loss: 1.1606\n",
            "Epoch 24/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.6364 - val_loss: 1.2523\n",
            "Epoch 25/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.6455 - val_loss: 1.4790\n",
            "Epoch 26/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.6455 - val_loss: 1.7863\n",
            "Epoch 27/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.9925 - loss: 0.0136 - val_accuracy: 0.6545 - val_loss: 1.2720\n",
            "Epoch 28/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.6727 - val_loss: 1.3853\n",
            "Epoch 29/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9981 - loss: 0.0071 - val_accuracy: 0.6455 - val_loss: 1.3030\n",
            "Epoch 30/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.7000 - val_loss: 1.2260\n",
            "Epoch 31/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.6818 - val_loss: 1.3196\n",
            "Epoch 32/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9990 - loss: 0.0045 - val_accuracy: 0.6909 - val_loss: 1.2966\n",
            "Epoch 33/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.6818 - val_loss: 1.4810\n",
            "Epoch 34/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.6545 - val_loss: 1.5879\n",
            "Epoch 35/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7000 - val_loss: 1.5897\n",
            "Epoch 36/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.3670e-04 - val_accuracy: 0.6818 - val_loss: 1.6739\n",
            "Epoch 37/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.9648e-04 - val_accuracy: 0.6727 - val_loss: 1.7584\n",
            "Epoch 38/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.0109e-04 - val_accuracy: 0.6727 - val_loss: 1.7824\n",
            "Epoch 39/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.7734e-04 - val_accuracy: 0.6818 - val_loss: 1.7820\n",
            "Epoch 40/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5948e-04 - val_accuracy: 0.6727 - val_loss: 1.9008\n",
            "Epoch 41/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.1770e-04 - val_accuracy: 0.7091 - val_loss: 1.7620\n",
            "Epoch 42/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.4077e-04 - val_accuracy: 0.7091 - val_loss: 1.7566\n",
            "Epoch 43/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.5334e-04 - val_accuracy: 0.6818 - val_loss: 1.7893\n",
            "Epoch 44/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6909 - val_loss: 1.8639\n",
            "Epoch 45/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7091 - val_loss: 1.6444\n",
            "Epoch 46/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.5475e-04 - val_accuracy: 0.7182 - val_loss: 1.5857\n",
            "Epoch 47/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.2266e-04 - val_accuracy: 0.7182 - val_loss: 1.6573\n",
            "Epoch 48/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.3900e-04 - val_accuracy: 0.7182 - val_loss: 1.7033\n",
            "Epoch 49/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.6265e-04 - val_accuracy: 0.7455 - val_loss: 1.7322\n",
            "Epoch 50/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.7562e-04 - val_accuracy: 0.7545 - val_loss: 1.7593\n",
            "Epoch 51/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5026e-04 - val_accuracy: 0.7364 - val_loss: 1.8353\n",
            "Epoch 52/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.7220e-04 - val_accuracy: 0.7182 - val_loss: 1.8031\n",
            "Epoch 53/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.9208e-04 - val_accuracy: 0.7000 - val_loss: 1.8472\n",
            "Epoch 54/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9686e-04 - val_accuracy: 0.7273 - val_loss: 1.8389\n",
            "Epoch 55/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.6860e-04 - val_accuracy: 0.7273 - val_loss: 1.8618\n",
            "Epoch 56/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.6301e-04 - val_accuracy: 0.7091 - val_loss: 1.8815\n",
            "Epoch 57/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8543e-04 - val_accuracy: 0.7273 - val_loss: 1.9150\n",
            "Epoch 58/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.7605e-04 - val_accuracy: 0.7091 - val_loss: 1.9759\n",
            "Epoch 59/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5925e-04 - val_accuracy: 0.7273 - val_loss: 2.0243\n",
            "Epoch 60/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.4846e-04 - val_accuracy: 0.7182 - val_loss: 1.9606\n",
            "Epoch 61/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0514e-04 - val_accuracy: 0.7000 - val_loss: 1.9352\n",
            "Epoch 62/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5170e-04 - val_accuracy: 0.7182 - val_loss: 1.8572\n",
            "Epoch 63/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.5466e-04 - val_accuracy: 0.7182 - val_loss: 1.7838\n",
            "Epoch 64/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.6074e-04 - val_accuracy: 0.7000 - val_loss: 1.7901\n",
            "Epoch 65/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1489e-04 - val_accuracy: 0.7091 - val_loss: 1.8173\n",
            "Epoch 66/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5359e-04 - val_accuracy: 0.7091 - val_loss: 1.8423\n",
            "Epoch 67/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.0784e-05 - val_accuracy: 0.7182 - val_loss: 1.8722\n",
            "Epoch 68/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2095e-04 - val_accuracy: 0.7182 - val_loss: 1.8726\n",
            "Epoch 69/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4756e-04 - val_accuracy: 0.7364 - val_loss: 1.8395\n",
            "Epoch 70/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8604e-04 - val_accuracy: 0.7273 - val_loss: 1.8582\n",
            "Epoch 71/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.7740e-05 - val_accuracy: 0.7273 - val_loss: 1.8690\n",
            "Epoch 72/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.8658e-05 - val_accuracy: 0.7182 - val_loss: 1.8989\n",
            "Epoch 73/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0020e-04 - val_accuracy: 0.7091 - val_loss: 1.9201\n",
            "Epoch 74/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.3809e-04 - val_accuracy: 0.7273 - val_loss: 1.9552\n",
            "Epoch 75/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.7043e-05 - val_accuracy: 0.7182 - val_loss: 1.9744\n",
            "Epoch 76/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.2204e-05 - val_accuracy: 0.7364 - val_loss: 1.9669\n",
            "Epoch 77/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0123e-04 - val_accuracy: 0.7364 - val_loss: 1.9789\n",
            "Epoch 78/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3801e-04 - val_accuracy: 0.7273 - val_loss: 1.9893\n",
            "Epoch 79/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.9616e-05 - val_accuracy: 0.7273 - val_loss: 2.0010\n",
            "Epoch 80/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.7980e-05 - val_accuracy: 0.7364 - val_loss: 2.0149\n",
            "Epoch 81/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1681e-05 - val_accuracy: 0.7364 - val_loss: 2.0256\n",
            "Epoch 82/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.8819e-05 - val_accuracy: 0.7273 - val_loss: 2.0356\n",
            "Epoch 83/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.6369e-05 - val_accuracy: 0.7273 - val_loss: 2.0493\n",
            "Epoch 84/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.1401e-05 - val_accuracy: 0.7182 - val_loss: 2.0769\n",
            "Epoch 85/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.5662e-05 - val_accuracy: 0.6909 - val_loss: 2.2099\n",
            "Epoch 86/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.6559e-04 - val_accuracy: 0.7364 - val_loss: 1.9952\n",
            "Epoch 87/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0595e-04 - val_accuracy: 0.7273 - val_loss: 1.9827\n",
            "Epoch 88/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.4772e-05 - val_accuracy: 0.7182 - val_loss: 1.9436\n",
            "Epoch 89/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.9100e-05 - val_accuracy: 0.7182 - val_loss: 1.9463\n",
            "Epoch 90/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.3029e-05 - val_accuracy: 0.7091 - val_loss: 1.9663\n",
            "Epoch 91/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.3715e-05 - val_accuracy: 0.7091 - val_loss: 1.9835\n",
            "Epoch 92/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.9945e-05 - val_accuracy: 0.7000 - val_loss: 1.9502\n",
            "Epoch 93/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.2282e-05 - val_accuracy: 0.7000 - val_loss: 1.9534\n",
            "Epoch 94/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.8358e-05 - val_accuracy: 0.7182 - val_loss: 1.9922\n",
            "Epoch 95/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.0275e-05 - val_accuracy: 0.7273 - val_loss: 2.0053\n",
            "Epoch 96/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2216e-05 - val_accuracy: 0.7182 - val_loss: 2.0104\n",
            "Epoch 97/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.8453e-05 - val_accuracy: 0.7182 - val_loss: 2.0103\n",
            "Epoch 98/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.2374e-05 - val_accuracy: 0.6909 - val_loss: 2.0032\n",
            "Epoch 99/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.3201e-05 - val_accuracy: 0.7091 - val_loss: 2.0189\n",
            "Epoch 100/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2721e-05 - val_accuracy: 0.7091 - val_loss: 2.0354\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7846076298d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate CNN on validation set\n",
        "cnn_loss, cnn_acc = cnn_model.evaluate(validation_generator)\n",
        "print(\"CNN Accuracy:\", cnn_acc)\n",
        "\n",
        "# Save CNN model\n",
        "cnn_model.save('/content/models/cnn_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYnnJx6jHkFd",
        "outputId": "5a804d22-16e4-4b27-f033-81edab142f18"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - accuracy: 0.7670 - loss: 1.6217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Accuracy: 0.7090908885002136\n"
          ]
        }
      ]
    }
  ]
}